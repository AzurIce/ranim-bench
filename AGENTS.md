# ranim-bench & ranim

## Project Overview

This workspace contains **ranim-bench**, a custom benchmarking harness designed for the **ranim** animation engine.

*   **ranim-bench**: The root project. It is a CLI tool (`src/main.rs`) that automates the execution of benchmarks. It handles:
    *   Verifying the git state of the `ranim` submodule.
    *   Collecting system information (CPU, Memory, GPU).
    *   Invoking `cargo criterion` within the `ranim/benches` directory.
    *   Structuring and saving output data (JSON) to the `db/` directory, organized by commit hash and run name.
*   **ranim** (Submodule): A Rust animation engine inspired by Manim. It resides in the `ranim/` directory and contains the core logic and the actual benchmark implementations (`ranim/benches/`).

## Directory Structure

*   `src/`: Source code for the `ranim-bench` harness.
*   `ranim/`: The `ranim` source code (submodule).
    *   `ranim/benches/`: Benchmark definitions (`eval`, `render`, `extract`).
    *   `ranim/justfile`: Task runner configuration for `ranim`.
*   `db/`: Storage for benchmark results (primary data, git-tracked).
    *   Structure: `db/<commit_hash>/<run_name>/...`
    *   Each run directory contains `run.json` (system info + benchmark IDs) and per-benchmark JSON files.
    *   Note: `db/db.json` is no longer used. The `graph` command scans `db/` directly.
*   `web/`: Web frontend for visualizing benchmark results.
    *   `web/public/all-data.json`: Aggregated benchmark data (generated by `graph` command, gitignored).
    *   `web/public/git-graph.json`: Git commit graph (generated by `graph` command, gitignored).

## Data Flow

```
bench command → writes raw data to db/<hash>/<name>/*.json (git-tracked)
                        ↓
                graph command (scans db/)
                        ↓
        web/public/all-data.json  (aggregated, gitignored)
        web/public/git-graph.json (git graph, gitignored)
                        ↓
            web frontend (2 fetches total)
```

## Benchmark Suite

There are 22 benchmarks across 3 groups:

| Group | Benchmark | Parameters |
|-------|-----------|------------|
| eval | eval_static_squares | 10, 100, 1000 |
| eval | eval_transform_squares | 10, 100, 1000 |
| extract | polygon | 5, 10, 20, 40 |
| extract | square, rectangle, circle, arc | (none) |
| render | static_squares | 5, 10, 20, 40 |
| render | transform_squares | 5, 10, 20, 40 |

The `render` group benchmarks are the most time-consuming (especially `render/transform_squares/40`, which can take ~10 minutes alone). A full benchmark run takes approximately 20-30 minutes.

## Usage

### Running Benchmarks

**Recommended: Auto-benchmark all missing commits**

```bash
cargo run --release -- bench-missing --name <machine_name>
```

This single command will:
1. Fetch `origin` in the ranim submodule
2. Find all PR-merged commits on `origin/main` (matching `(#NNN)` pattern)
3. Check which commits are missing benchmarks for this machine
4. Checkout and benchmark each missing commit (oldest first)
5. Restore the submodule to the latest benchmarked commit

Options:
*   `--name <string>`: (Required) Machine name (e.g., "macbookpro", "aorus").
*   `--force`: Re-run benchmarks even if data already exists.
*   `--dry-run`: Only show what would be benchmarked, don't run.

**Manual: Single commit benchmark**

```bash
cargo run --release -- bench --name <run_name> [--allow-dirty] [--force]
```

*   `--allow-dirty`: Skip clean check. Required when submodule is in detached HEAD state.
*   `--force`: Overwrite existing output.

**Other subcommands:**

*   `cargo run --release -- graph`: Scan `db/`, generate `all-data.json` and `git-graph.json` for web.
*   `cargo run --release -- sync`: Rebuild `run.json` manifests from existing benchmark data.

### Developing `ranim`

If you are working on the `ranim` engine itself (inside the `ranim/` directory), standard Rust workflows apply.

*   **Build**: `cargo build`
*   **Test**: `cargo test`
*   **Task Runner**: The project uses `just`.
    *   `just fmt`: Format code.
    *   `just lint`: Run clippy and build docs.
    *   `just clean`: Remove logs/artifacts.

## Benchmark Workflow for Agents

When asked to run benchmarks for new/missing commits:

```bash
# Preview what needs to be benchmarked
cargo run --release -- bench-missing --name macbookpro --dry-run

# Run all missing benchmarks (set generous timeout, ~30min per commit)
cargo run --release -- bench-missing --name macbookpro

# Regenerate web data after benchmarking
cargo run --release -- graph
```

That's it. The `bench-missing` command handles fetch, checkout, and restore automatically.

## Key Configuration

*   **Cargo.toml**: Dependencies for the harness (clap, sysinfo, criterion, wgpu, git-graph).
*   **ranim/benches/Cargo.toml**: Defines the `eval`, `render`, and `extract` benchmark targets (all with `harness = false`, using Criterion directly).

## Notes

*   The harness requires the `ranim` submodule to be initialized (`git submodule update --init --recursive`).
*   Output logs for the harness use `tracing` and print to stdout/stderr.
*   The `render` benchmarks require GPU access (Metal on macOS, Vulkan on Windows/Linux).
*   Benchmark results include `slope`, `mean`, `median`, `median_abs_dev` (in nanoseconds), `measured_values`, `iteration_count`, and `change` vs. previous run.
*   Each benchmark run takes ~20-30 minutes. Set a generous timeout (at least 3600 seconds) when running via agents.
